"""–°–∫—Ä–∏–ø—Ç –¥–ª—è –æ—Ü–µ–Ω–∫–∏ retrieval —Å–∏—Å—Ç–µ–º—ã"""

import asyncio
import json
import logging
import sys
from pathlib import Path

# –î–æ–±–∞–≤–ª—è–µ–º src –≤ –ø—É—Ç—å
src_path = Path(__file__).parent.parent
if str(src_path) not in sys.path:
    sys.path.insert(0, str(src_path))

from tqdm import tqdm
from tplexity.retriever.retriever_service import RetrieverService
from eval.metrics import precision_at_k, recall_at_k

logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s - %(levelname)s - %(message)s",
)
logger = logging.getLogger(__name__)


async def evaluate_retrieval(
    queries_path: str = "src/eval/eval_data/queries.json",
    top_k: int = 5,
    use_rerank: bool = False,
    output_path: str = "src/eval/results.json",
    num_queries: int = None,
):
    """
    –û—Ü–µ–Ω–∫–∞ retrieval —Å–∏—Å—Ç–µ–º—ã
    
    Args:
        queries_path: –ü—É—Ç—å –∫ —Ñ–∞–π–ª—É —Å –∑–∞–ø—Ä–æ—Å–∞–º–∏
        top_k: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –¥–ª—è –ø–æ–∏—Å–∫–∞ (K)
        use_rerank: –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –ª–∏ reranking
        output_path: –ü—É—Ç—å –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
        num_queries: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∑–∞–ø—Ä–æ—Å–æ–≤ –¥–ª—è –æ—Ü–µ–Ω–∫–∏ (None = –≤—Å–µ)
    """
    logger.info("=" * 80)
    logger.info("EVALUATION RETRIEVAL")
    logger.info("=" * 80)

    # –ó–∞–≥—Ä—É–∑–∫–∞ –∑–∞–ø—Ä–æ—Å–æ–≤
    logger.info(f"üîÑ –ó–∞–≥—Ä—É–∑–∫–∞ –∑–∞–ø—Ä–æ—Å–æ–≤ –∏–∑ {queries_path}...")
    with open(queries_path, "r", encoding="utf-8") as f:
        all_queries = json.load(f)

    if num_queries is not None and num_queries < len(all_queries):
        queries = all_queries[:num_queries]
        logger.info(f"‚úÖ –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è {num_queries} –∑–∞–ø—Ä–æ—Å–æ–≤ –∏–∑ {len(all_queries)}")
    else:
        queries = all_queries
        logger.info(f"‚úÖ –ò—Å–ø–æ–ª—å–∑—É—é—Ç—Å—è –≤—Å–µ {len(queries)} –∑–∞–ø—Ä–æ—Å–æ–≤")

    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è RetrieverService
    logger.info("üîÑ –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è RetrieverService...")
    retriever = RetrieverService()

    # –û—Ü–µ–Ω–∫–∞ –¥–ª—è —Ä–∞–∑–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π K
    k_values = [1, 3, 5, 10]
    k_values = [k for k in k_values if k <= top_k]
    
    logger.info(f"\nüîç –ù–∞—á–∞–ª–æ –æ—Ü–µ–Ω–∫–∏ (top_k={top_k}, use_rerank={use_rerank})...")
    logger.info(f"–ë—É–¥—É—Ç –≤—ã—á–∏—Å–ª–µ–Ω—ã –º–µ—Ç—Ä–∏–∫–∏ –¥–ª—è K: {k_values}")

    # –•—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ K
    all_precisions = {k: [] for k in k_values}
    all_recalls = {k: [] for k in k_values}
    results_detailed = []

    for idx, query_data in enumerate(tqdm(queries, desc="Evaluating")):
        query_text = query_data["query"]
        ground_truth_id = f"{query_data['id_channel']}_{query_data['id_message']}"

        # –í—ã–ø–æ–ª–Ω—è–µ–º –ø–æ–∏—Å–∫
        try:
            search_results = await retriever.search(
                query=query_text,
                top_k=top_k * 2,  # –ë–µ—Ä–µ–º –±–æ–ª—å—à–µ –¥–ª—è reranking
                top_n=top_k,
                use_rerank=use_rerank,
            )
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–∏—Å–∫–µ –¥–ª—è –∑–∞–ø—Ä–æ—Å–∞ {idx+1}: {e}")
            for k in k_values:
                all_precisions[k].append(0.0)
                all_recalls[k].append(0.0)
            continue

        # –ò–∑–≤–ª–µ–∫–∞–µ–º ID –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤
        retrieved_ids = [doc_id for doc_id, _, _, _ in search_results]

        # –î–ª—è –∫–∞–∂–¥–æ–≥–æ K –≤—ã—á–∏—Å–ª—è–µ–º –º–µ—Ç—Ä–∏–∫–∏
        query_metrics = {}
        for k in k_values:
            # Ground truth - —Ç–æ–ª—å–∫–æ –æ–¥–∏–Ω —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–π –¥–æ–∫—É–º–µ–Ω—Ç
            relevant_ids = [ground_truth_id]
            retrieved_k = retrieved_ids[:k]

            # Precision@K = 1/K –µ—Å–ª–∏ –¥–æ–∫—É–º–µ–Ω—Ç –Ω–∞–π–¥–µ–Ω –≤ —Ç–æ–ø-K, –∏–Ω–∞—á–µ 0
            # Recall@K = 1 –µ—Å–ª–∏ –¥–æ–∫—É–º–µ–Ω—Ç –Ω–∞–π–¥–µ–Ω –≤ —Ç–æ–ø-K, –∏–Ω–∞—á–µ 0 (—Ç–∞–∫ –∫–∞–∫ —É –Ω–∞—Å —Ç–æ–ª—å–∫–æ 1 —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–π –¥–æ–∫—É–º–µ–Ω—Ç)
            precision = precision_at_k(retrieved_k, relevant_ids, k)
            recall = recall_at_k(retrieved_k, relevant_ids, k)

            all_precisions[k].append(precision)
            all_recalls[k].append(recall)
            
            query_metrics[f"precision@{k}"] = precision
            query_metrics[f"recall@{k}"] = recall

        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –¥–µ—Ç–∞–ª—å–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é
        results_detailed.append({
            "query": query_text,
            "query_id": query_data.get("id_message"),
            "ground_truth_id": ground_truth_id,
            "retrieved_ids": retrieved_ids[:top_k],
            "found_in_results": ground_truth_id in retrieved_ids,
            "position": retrieved_ids.index(ground_truth_id) + 1 if ground_truth_id in retrieved_ids else None,
            **query_metrics,
        })

        if (idx + 1) % 50 == 0:
            logger.info(f"–û–±—Ä–∞–±–æ—Ç–∞–Ω–æ {idx + 1}/{len(queries)} –∑–∞–ø—Ä–æ—Å–æ–≤...")

    # –í—ã—á–∏—Å–ª—è–µ–º —Å—Ä–µ–¥–Ω–∏–µ –º–µ—Ç—Ä–∏–∫–∏ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ K
    avg_metrics = {}
    for k in k_values:
        avg_precision = sum(all_precisions[k]) / len(all_precisions[k]) if all_precisions[k] else 0.0
        avg_recall = sum(all_recalls[k]) / len(all_recalls[k]) if all_recalls[k] else 0.0
        avg_metrics[f"precision@{k}"] = avg_precision
        avg_metrics[f"recall@{k}"] = avg_recall

    # –†–µ–∑—É–ª—å—Ç–∞—Ç—ã
    results = {
        "config": {
            "num_queries": len(queries),
            "top_k": top_k,
            "use_rerank": use_rerank,
            "k_values": k_values,
        },
        "metrics": avg_metrics,
        "detailed_results": results_detailed,
    }

    # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
    output_path = Path(output_path)
    output_path.parent.mkdir(parents=True, exist_ok=True)

    with open(output_path, "w", encoding="utf-8") as f:
        json.dump(results, f, ensure_ascii=False, indent=2)

    logger.info(f"\n‚úÖ –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ {output_path}")

    # –í—ã–≤–æ–¥ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
    logger.info("\n" + "=" * 80)
    logger.info("üìä –†–ï–ó–£–õ–¨–¢–ê–¢–´ EVALUATION")
    logger.info("=" * 80)
    logger.info(f"–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∑–∞–ø—Ä–æ—Å–æ–≤: {len(queries)}")
    logger.info(f"Top-K: {top_k}")
    logger.info(f"Use rerank: {use_rerank}")
    logger.info(f"\nüéØ –ú–µ—Ç—Ä–∏–∫–∏:")
    
    for k in k_values:
        precision = avg_metrics[f"precision@{k}"]
        recall = avg_metrics[f"recall@{k}"]
        logger.info(f"  K={k}:")
        logger.info(f"    Precision@{k}: {precision:.4f} ({precision*100:.2f}%)")
        logger.info(f"    Recall@{k}: {recall:.4f} ({recall*100:.2f}%)")
    
    logger.info("=" * 80)

    return results


async def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è"""
    
    # === –ö–û–ù–§–ò–ì–£–†–ê–¶–ò–Ø ===
    # –ó–¥–µ—Å—å –º–æ–∂–Ω–æ –ª–µ–≥–∫–æ –∏–∑–º–µ–Ω–∏—Ç—å –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –æ—Ü–µ–Ω–∫–∏
    
    CONFIG = {
        "queries_path": "src/eval/eval_data/queries.json",
        "top_k": 10,  # <-- –ò–∑–º–µ–Ω–∏—Ç–µ K –∑–¥–µ—Å—å
        "use_rerank": False,  # <-- –í–∫–ª—é—á–∏—Ç—å/–≤—ã–∫–ª—é—á–∏—Ç—å reranking
        "output_path": "src/eval/results.json",
        "num_queries": None,  # None = –≤—Å–µ –∑–∞–ø—Ä–æ—Å—ã, –∏–ª–∏ —É–∫–∞–∂–∏—Ç–µ —á–∏—Å–ª–æ
    }
    
    # ====================

    logger.info("üöÄ –ó–∞–ø—É—Å–∫ evaluation...")
    logger.info(f"–ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è:")
    for key, value in CONFIG.items():
        logger.info(f"  {key}: {value}")

    try:
        await evaluate_retrieval(**CONFIG)
    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–∏ evaluation: {e}")
        raise


if __name__ == "__main__":
    asyncio.run(main())

