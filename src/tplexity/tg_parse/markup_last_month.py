"""
–°–∫—Ä–∏–ø—Ç –¥–ª—è —Ä–∞–∑–º–µ—Ç–∫–∏ –¥–∞–Ω–Ω—ã—Ö –∑–∞ –ø–æ—Å–ª–µ–¥–Ω–∏–µ 2 –Ω–µ–¥–µ–ª–∏.

–°–∫–∞—á–∏–≤–∞–µ—Ç –ø–æ—Å—Ç—ã –∑–∞ –ø–æ—Å–ª–µ–¥–Ω–∏–µ 14 –¥–Ω–µ–π, –æ—á–∏—â–∞–µ—Ç –≤–µ–∫—Ç–æ—Ä–Ω—É—é –ë–î,
–æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –∏—Ö —á–µ—Ä–µ–∑ LLM –¥–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –∞–∫—Ç—É–∞–ª—å–Ω–æ—Å—Ç–∏ –∏ –æ—Ç–ø—Ä–∞–≤–ª—è–µ—Ç –≤ retriever.
"""

import asyncio
import logging
from datetime import UTC, datetime, timedelta
from pathlib import Path

import httpx

from tplexity.tg_parse.config import settings
from tplexity.tg_parse.llm_batcher import get_batcher
from tplexity.tg_parse.relevance_analyzer import calculate_delete_date
from tplexity.tg_parse.telegram_downloader import TelegramDownloader

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s - %(name)s - %(levelname)s - %(message)s",
)
logger = logging.getLogger(__name__)


async def clear_database(retriever_url: str) -> bool:
    """
    –û—á–∏—â–∞–µ—Ç –≤–µ–∫—Ç–æ—Ä–Ω—É—é –ë–î, —É–¥–∞–ª—è—è –≤—Å–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã.

    Args:
        retriever_url: URL retriever API

    Returns:
        True –µ—Å–ª–∏ —É—Å–ø–µ—à–Ω–æ, False –≤ –ø—Ä–æ—Ç–∏–≤–Ω–æ–º —Å–ª—É—á–∞–µ
    """
    try:
        delete_url = f"{retriever_url.rstrip('/')}/retriever/documents/all"
        logger.info(f"üóëÔ∏è –û—á–∏—Å—Ç–∫–∞ –≤–µ–∫—Ç–æ—Ä–Ω–æ–π –ë–î: {delete_url}")

        async with httpx.AsyncClient(
            limits=httpx.Limits(max_keepalive_connections=10, max_connections=20),
            timeout=httpx.Timeout(60.0, connect=10.0),
        ) as client:
            response = await client.delete(delete_url, timeout=60.0)
            response.raise_for_status()

        logger.info("‚úÖ –í–µ–∫—Ç–æ—Ä–Ω–∞—è –ë–î —É—Å–ø–µ—à–Ω–æ –æ—á–∏—â–µ–Ω–∞")
        return True
    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ—á–∏—Å—Ç–∫–µ –ë–î: {e}")
        return False


async def send_posts_to_retriever(
    posts: list[dict],
    channel: str,
    retriever_url: str,
    llm_batcher,
    llm_provider: str,
    batch_size: int = 50,
    channel_titles: dict[str, str] | None = None,
) -> tuple[int, int]:
    """
    –û—Ç–ø—Ä–∞–≤–ª—è–µ—Ç –ø–æ—Å—Ç—ã –≤ retriever —Å –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ–º –∞–∫—Ç—É–∞–ª—å–Ω–æ—Å—Ç–∏ —á–µ—Ä–µ–∑ LLM.

    Args:
        posts: –°–ø–∏—Å–æ–∫ –ø–æ—Å—Ç–æ–≤ –¥–ª—è –æ—Ç–ø—Ä–∞–≤–∫–∏
        channel: –ù–∞–∑–≤–∞–Ω–∏–µ –∫–∞–Ω–∞–ª–∞
        retriever_url: URL retriever API
        llm_batcher: –ë–∞—Ç—á–µ—Ä –¥–ª—è LLM –∑–∞–ø—Ä–æ—Å–æ–≤
        llm_provider: –ü—Ä–æ–≤–∞–π–¥–µ—Ä LLM
        batch_size: –†–∞–∑–º–µ—Ä –±–∞—Ç—á–∞ –¥–ª—è –æ—Ç–ø—Ä–∞–≤–∫–∏
        channel_titles: –°–ª–æ–≤–∞—Ä—å —Å –Ω–∞–∑–≤–∞–Ω–∏—è–º–∏ –∫–∞–Ω–∞–ª–æ–≤

    Returns:
        –ö–æ—Ä—Ç–µ–∂ (—É—Å–ø–µ—à–Ω–æ –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω–æ, –æ—à–∏–±–æ–∫)
    """
    if not posts:
        return 0, 0

    documents_url = f"{retriever_url.rstrip('/')}/retriever/documents"
    success_count = 0
    error_count = 0

    # HTTP –∫–ª–∏–µ–Ω—Ç —Å connection pooling
    async with httpx.AsyncClient(
        limits=httpx.Limits(max_keepalive_connections=10, max_connections=20),
        timeout=httpx.Timeout(30.0, connect=10.0),
    ) as http_client:
        # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –ø–æ—Å—Ç—ã –±–∞—Ç—á–∞–º–∏
        for i in range(0, len(posts), batch_size):
            batch = posts[i : i + batch_size]
            prepared_posts: list[dict] = []
            llm_tasks = []

            for post in batch:
                text = (post.get("text") or "").strip()
                if not text:
                    continue

                # –î–æ–±–∞–≤–ª—è–µ–º –≤—Ä–µ–º—è –ø–æ—Å—Ç–∞ –≤ –∫–æ–Ω–µ—Ü —Ç–µ–∫—Å—Ç–∞
                date_str = post.get("date")
                post_date = None
                if date_str:
                    try:
                        # –ü–∞—Ä—Å–∏–º –¥–∞—Ç—É –∏–∑ ISO —Ñ–æ—Ä–º–∞—Ç–∞
                        if date_str.endswith("Z"):
                            date_str = date_str.replace("Z", "+00:00")

                        if "T" in date_str:
                            post_date = datetime.fromisoformat(date_str)
                        else:
                            post_date = datetime.fromisoformat(f"{date_str}T00:00:00")

                        formatted_date = post_date.strftime("%Y-%m-%d %H:%M:%S")
                        text = f"{text}\n\n{formatted_date}"
                    except (ValueError, AttributeError) as e:
                        logger.debug(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å —Ä–∞—Å–ø–∞—Ä—Å–∏—Ç—å –¥–∞—Ç—É: {date_str}, –æ—à–∏–±–∫–∞: {e}")

                # –§–æ—Ä–º–∏—Ä—É–µ–º –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ
                metadata = {k: v for k, v in post.items() if k != "text"}
                metadata["channel_name"] = channel

                if channel_titles:
                    channel_title = channel_titles.get(channel, channel)
                    metadata["channel_title"] = channel_title
                else:
                    metadata["channel_title"] = channel

                prepared_posts.append(
                    {
                        "text": text,
                        "metadata": metadata,
                        "post_date": post_date,
                        "original_post_id": post.get("id"),
                    }
                )
                llm_tasks.append(llm_batcher.determine_relevance_days(text, llm_provider))

            if not prepared_posts:
                continue

            # –í—ã–ø–æ–ª–Ω—è–µ–º LLM-—Ä–∞–∑–º–µ—Ç–∫—É –∞—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ –±–∞—Ç—á–µ–º
            llm_results = await asyncio.gather(*llm_tasks, return_exceptions=True)

            documents = []
            for prepared, result in zip(prepared_posts, llm_results, strict=False):
                if isinstance(result, Exception):
                    logger.warning(
                        f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–∏ –∞–∫—Ç—É–∞–ª—å–Ω–æ—Å—Ç–∏ –ø–æ—Å—Ç–∞ {prepared.get('original_post_id')}: {result}"
                    )
                    documents.append(
                        {"text": prepared["text"], "metadata": prepared["metadata"]}
                    )
                    continue

                relevance_days, _ = result
                delete_date = calculate_delete_date(relevance_days, prepared["post_date"])
                prepared["metadata"]["delete_date"] = delete_date
                documents.append({"text": prepared["text"], "metadata": prepared["metadata"]})

            if not documents:
                continue

            try:
                response = await http_client.post(
                    documents_url, json={"documents": documents}, timeout=60.0
                )
                response.raise_for_status()
                success_count += len(documents)
                logger.info(
                    f"üì§ –û—Ç–ø—Ä–∞–≤–ª–µ–Ω–æ {len(documents)} –ø–æ—Å—Ç–æ–≤ –∏–∑ {channel} "
                    f"(–±–∞—Ç—á {i // batch_size + 1}/{(len(posts) + batch_size - 1) // batch_size})"
                )
            except Exception as e:
                error_count += len(documents)
                logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ—Ç–ø—Ä–∞–≤–∫–µ –±–∞—Ç—á–∞ –∏–∑ {channel}: {e}")

    return success_count, error_count


async def markup_last_month(days: int = 14):
    """
    –†–∞–∑–º–µ—á–∞–µ—Ç –¥–∞–Ω–Ω—ã–µ –∑–∞ –ø–æ—Å–ª–µ–¥–Ω–∏–µ N –¥–Ω–µ–π.

    Args:
        days: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –¥–Ω–µ–π –Ω–∞–∑–∞–¥ –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é 14 - 2 –Ω–µ–¥–µ–ª–∏)
    """
    logger.info("üöÄ –ó–∞–ø—É—Å–∫ —Ä–∞–∑–º–µ—Ç–∫–∏ –¥–∞–Ω–Ω—ã—Ö –∑–∞ –ø–æ—Å–ª–µ–¥–Ω–∏–µ 2 –Ω–µ–¥–µ–ª–∏")
    logger.info(f"üìÖ –ü–µ—Ä–∏–æ–¥: –ø–æ—Å–ª–µ–¥–Ω–∏–µ {days} –¥–Ω–µ–π")

    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é
    if not settings.api_id or not settings.api_hash:
        logger.error("‚ùå –ù–µ —É–∫–∞–∑–∞–Ω—ã API_ID –∏–ª–∏ API_HASH –≤ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏")
        return

    channels_list = settings.get_channels_list()
    if not channels_list:
        logger.error("‚ùå –°–ø–∏—Å–æ–∫ –∫–∞–Ω–∞–ª–æ–≤ –ø—É—Å—Ç")
        return

    if not settings.webhook_url:
        logger.error("‚ùå –ù–µ —É–∫–∞–∑–∞–Ω WEBHOOK_URL –≤ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏")
        return

    retriever_url = settings.webhook_url.rsplit("/retriever", 1)[0]
    logger.info(f"üì° Retriever URL: {retriever_url}")
    logger.info(f"üìã –ö–∞–Ω–∞–ª—ã –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏: {', '.join(channels_list)}")

    # –û—á–∏—â–∞–µ–º –≤–µ–∫—Ç–æ—Ä–Ω—É—é –ë–î –ø–µ—Ä–µ–¥ —Ä–∞–∑–º–µ—Ç–∫–æ–π
    logger.info("=" * 60)
    logger.info("üóëÔ∏è –û—á–∏—Å—Ç–∫–∞ –≤–µ–∫—Ç–æ—Ä–Ω–æ–π –ë–î –ø–µ—Ä–µ–¥ —Ä–∞–∑–º–µ—Ç–∫–æ–π...")
    if not await clear_database(retriever_url):
        logger.error("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –æ—á–∏—Å—Ç–∏—Ç—å –ë–î, –ø—Ä–µ—Ä—ã–≤–∞–µ–º –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–µ")
        return
    logger.info("=" * 60)

    # –í—ã—á–∏—Å–ª—è–µ–º –¥–∞—Ç—É N –¥–Ω–µ–π –Ω–∞–∑–∞–¥
    days_ago = datetime.now(UTC) - timedelta(days=days)
    logger.info(f"üìÖ –ó–∞–≥—Ä—É–∂–∞–µ–º –ø–æ—Å—Ç—ã —Å {days_ago.strftime('%Y-%m-%d %H:%M:%S UTC')}")

    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –∫–æ—Ä–µ–Ω—å –ø—Ä–æ–µ–∫—Ç–∞
    project_root = Path(__file__).parent.parent.parent.parent
    session_path = project_root / settings.session_name

    # –°–æ–∑–¥–∞–µ–º TelegramDownloader
    logger.info("üîß –°–æ–∑–¥–∞–Ω–∏–µ TelegramDownloader...")
    downloader = TelegramDownloader(
        api_id=settings.api_id,
        api_hash=settings.api_hash,
        session_name=str(session_path),
        session_string=settings.session_string,
        download_path=str(project_root / settings.data_dir / "telegram"),
    )

    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º LLM –±–∞—Ç—á–µ—Ä
    llm_batcher = get_batcher(settings.llm_provider)
    await llm_batcher.start()
    logger.info("‚úÖ LLM –±–∞—Ç—á–µ—Ä –∑–∞–ø—É—â–µ–Ω")

    try:
        # –ü–æ–¥–∫–ª—é—á–∞–µ–º—Å—è –∫ Telegram
        logger.info("üîå –ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ Telegram...")
        try:
            await downloader.client.connect()
            logger.info("‚úÖ –°–æ–µ–¥–∏–Ω–µ–Ω–∏–µ —Å Telegram —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–æ")
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–∏ –∫ Telegram: {e}", exc_info=True)
            return

        logger.info("üîç –ü—Ä–æ–≤–µ—Ä–∫–∞ –∞–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏–∏...")
        is_authorized = await downloader.client.is_user_authorized()
        logger.info(f"üîç –°—Ç–∞—Ç—É—Å –∞–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏–∏: {is_authorized}")

        if not is_authorized:
            error_msg = (
                "Telegram –∫–ª–∏–µ–Ω—Ç –Ω–µ –∞–≤—Ç–æ—Ä–∏–∑–æ–≤–∞–Ω. –¢—Ä–µ–±—É–µ—Ç—Å—è –∞–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏—è.\n"
                f"–ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è: {'—Å—Ç—Ä–æ–∫–∞ —Å–µ—Å—Å–∏–∏' if settings.session_string else f'—Ñ–∞–π–ª —Å–µ—Å—Å–∏–∏ ({session_path})'}\n"
                "–ó–∞–ø—É—Å—Ç–∏—Ç–µ —Å–∫—Ä–∏–ø—Ç: poetry run python src/tplexity/tg_parse/authorize_telegram.py"
            )
            logger.error(f"‚ùå {error_msg}")
            return

        logger.info("‚úÖ –ü–æ–¥–∫–ª—é—á–µ–Ω–æ –∫ Telegram –∏ –∞–≤—Ç–æ—Ä–∏–∑–æ–≤–∞–Ω–æ")

        total_posts_downloaded = 0
        total_posts_sent = 0
        total_errors = 0

        # –ü–æ–ª—É—á–∞–µ–º –Ω–∞–∑–≤–∞–Ω–∏—è –∫–∞–Ω–∞–ª–æ–≤
        channel_titles: dict[str, str] = {}
        for channel in channels_list:
            try:
                entity = await downloader.client.get_entity(channel)
                channel_title = getattr(entity, "title", None) or channel
                channel_titles[channel] = channel_title
                logger.info(f"üì∫ –ö–∞–Ω–∞–ª {channel}: –Ω–∞–∑–≤–∞–Ω–∏–µ '{channel_title}'")
            except Exception as e:
                logger.warning(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –Ω–∞–∑–≤–∞–Ω–∏–µ –∫–∞–Ω–∞–ª–∞ {channel}: {e}")
                channel_titles[channel] = channel

        # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –∫–∞–∂–¥—ã–π –∫–∞–Ω–∞–ª
        for channel_idx, channel in enumerate(channels_list, 1):
            logger.info(
                f"\n{'='*60}\n"
                f"üì• –û–±—Ä–∞–±–æ—Ç–∫–∞ –∫–∞–Ω–∞–ª–∞ {channel_idx}/{len(channels_list)}: {channel}\n"
                f"{'='*60}"
            )

            try:
                # –°–∫–∞—á–∏–≤–∞–µ–º —Å–æ–æ–±—â–µ–Ω–∏—è –∑–∞ –ø–æ—Å–ª–µ–¥–Ω–∏–µ N –¥–Ω–µ–π
                logger.info(f"üì• –°–∫–∞—á–∏–≤–∞–Ω–∏–µ –ø–æ—Å—Ç–æ–≤ –∏–∑ {channel}...")
                all_messages = []

                async for message in downloader.client.iter_messages(
                    channel,
                    limit=None,
                    offset_date=None,  # –ù–∞—á–∏–Ω–∞–µ–º —Å —Å–∞–º—ã—Ö –Ω–æ–≤—ã—Ö
                    reverse=False,  # –û—Ç –Ω–æ–≤—ã—Ö –∫ —Å—Ç–∞—Ä—ã–º
                ):
                    if not hasattr(message, "date") or not message.date:
                        continue

                    # –ï—Å–ª–∏ —Å–æ–æ–±—â–µ–Ω–∏–µ —Å—Ç–∞—Ä—à–µ N –¥–Ω–µ–π, –ø—Ä–µ–∫—Ä–∞—â–∞–µ–º —Å–∫–∞—á–∏–≤–∞–Ω–∏–µ
                    if message.date < days_ago:
                        break

                    # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –≤ —Å–ª–æ–≤–∞—Ä—å
                    message_dict = await downloader._message_to_dict(message, channel)
                    all_messages.append(message_dict)

                    # –õ–æ–≥–∏—Ä—É–µ–º –ø—Ä–æ–≥—Ä–µ—Å—Å –∫–∞–∂–¥—ã–µ 50 —Å–æ–æ–±—â–µ–Ω–∏–π
                    if len(all_messages) % 50 == 0:
                        logger.info(
                            f"  üì• –°–∫–∞—á–∞–Ω–æ {len(all_messages)} —Å–æ–æ–±—â–µ–Ω–∏–π –∏–∑ {channel}..."
                        )

                # –§–∏–ª—å—Ç—Ä—É–µ–º —Å–æ–æ–±—â–µ–Ω–∏—è —Å —Ç–µ–∫—Å—Ç–æ–º
                messages_with_text = [
                    msg
                    for msg in all_messages
                    if msg.get("text")
                    and isinstance(msg.get("text"), str)
                    and msg.get("text").strip()
                ]

                total_posts_downloaded += len(messages_with_text)
                logger.info(
                    f"üìä –ö–∞–Ω–∞–ª {channel}: "
                    f"—Å–∫–∞—á–∞–Ω–æ {len(all_messages)} –ø–æ—Å—Ç–æ–≤, "
                    f"{len(messages_with_text)} —Å —Ç–µ–∫—Å—Ç–æ–º"
                )

                # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –ø–æ—Å—Ç—ã –≤ retriever —Å —Ä–∞–∑–º–µ—Ç–∫–æ–π —á–µ—Ä–µ–∑ LLM
                if messages_with_text:
                    success, errors = await send_posts_to_retriever(
                        messages_with_text,
                        channel,
                        retriever_url,
                        llm_batcher,
                        settings.llm_provider,
                        channel_titles=channel_titles,
                    )
                    total_posts_sent += success
                    total_errors += errors

                    logger.info(
                        f"‚úÖ –ö–∞–Ω–∞–ª {channel}: –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω–æ {success} –ø–æ—Å—Ç–æ–≤, –æ—à–∏–±–æ–∫: {errors}"
                    )
                else:
                    logger.warning(f"‚ö†Ô∏è –ö–∞–Ω–∞–ª {channel}: –Ω–µ—Ç –ø–æ—Å—Ç–æ–≤ —Å —Ç–µ–∫—Å—Ç–æ–º")

            except Exception as e:
                logger.error(
                    f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –∫–∞–Ω–∞–ª–∞ {channel}: {e}", exc_info=True
                )
                total_errors += 1

        # –ò—Ç–æ–≥–æ–≤–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        logger.info(
            f"\n{'='*60}\n"
            f"‚úÖ –†–∞–∑–º–µ—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö –∑–∞–≤–µ—Ä—à–µ–Ω–∞!\n"
            f"{'='*60}\n"
            f"üìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞:\n"
            f"  - –í—Å–µ–≥–æ —Å–∫–∞—á–∞–Ω–æ –ø–æ—Å—Ç–æ–≤: {total_posts_downloaded}\n"
            f"  - –£—Å–ø–µ—à–Ω–æ –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω–æ –≤ –ë–î: {total_posts_sent}\n"
            f"  - –û—à–∏–±–æ–∫: {total_errors}\n"
            f"{'='*60}"
        )

    except Exception as e:
        logger.error(f"‚ùå –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞: {e}", exc_info=True)
    finally:
        # –û—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º LLM –±–∞—Ç—á–µ—Ä
        await llm_batcher.stop()

        # –û—Ç–∫–ª—é—á–∞–µ–º—Å—è –æ—Ç Telegram
        try:
            await downloader.disconnect()
            logger.info("‚úÖ –û—Ç–∫–ª—é—á–µ–Ω–æ –æ—Ç Telegram")
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ—Ç–∫–ª—é—á–µ–Ω–∏–∏: {e}")


def main():
    """–¢–æ—á–∫–∞ –≤—Ö–æ–¥–∞ –¥–ª—è –∑–∞–ø—É—Å–∫–∞ —Å–∫—Ä–∏–ø—Ç–∞."""
    import sys

    # –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é 14 –¥–Ω–µ–π (2 –Ω–µ–¥–µ–ª–∏)
    days = 14
    if len(sys.argv) > 1:
        try:
            days = int(sys.argv[1])
        except ValueError:
            logger.warning(f"‚ö†Ô∏è –ù–µ–≤–µ—Ä–Ω—ã–π –∞—Ä–≥—É–º–µ–Ω—Ç {sys.argv[1]}, –∏—Å–ø–æ–ª—å–∑—É–µ–º 14 –¥–Ω–µ–π (2 –Ω–µ–¥–µ–ª–∏)")

    asyncio.run(markup_last_month(days=days))


if __name__ == "__main__":
    main()

