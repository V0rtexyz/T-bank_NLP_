{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# –û—Ü–µ–Ω–∫–∞ –º–µ—Ç—Ä–∏–∫ ReAct Router\n",
        "\n",
        "–≠—Ç–æ—Ç –Ω–æ—É—Ç–±—É–∫ –≤—ã—á–∏—Å–ª—è–µ—Ç –º–µ—Ç—Ä–∏–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞ —Ä–∞–±–æ—Ç—ã ReAct Router:\n",
        "- Recall (–ü–æ–ª–Ω–æ—Ç–∞)\n",
        "- Precision (–¢–æ—á–Ω–æ—Å—Ç—å)\n",
        "- F1-score\n",
        "- TP, FP, TN, FN (Confusion Matrix)\n",
        "\n",
        "ReAct Router —Ä–µ—à–∞–µ—Ç, –Ω—É–∂–µ–Ω –ª–∏ retriever –¥–ª—è –æ—Ç–≤–µ—Ç–∞ –Ω–∞ –∑–∞–ø—Ä–æ—Å.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üìÅ –ö–æ—Ä–Ω–µ–≤–∞—è –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –ø—Ä–æ–µ–∫—Ç–∞: /srv/nlp1/T-bank_NLP_-1\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "import sys\n",
        "from pathlib import Path\n",
        "from typing import Literal\n",
        "\n",
        "import asyncio\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# –î–æ–±–∞–≤–ª—è–µ–º –ø—É—Ç—å –∫ –ø—Ä–æ–µ–∫—Ç—É\n",
        "project_root = Path.cwd().parent.parent\n",
        "sys.path.insert(0, str(project_root / \"src\"))\n",
        "\n",
        "print(f\"üìÅ –ö–æ—Ä–Ω–µ–≤–∞—è –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –ø—Ä–æ–µ–∫—Ç–∞: {project_root}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ –ò–º–ø–æ—Ä—Ç—ã –≤—ã–ø–æ–ª–Ω–µ–Ω—ã —É—Å–ø–µ—à–Ω–æ\n"
          ]
        }
      ],
      "source": [
        "from tplexity.generation.generation_service import GenerationService\n",
        "from tplexity.generation.config import settings\n",
        "\n",
        "print(\"‚úÖ –ò–º–ø–æ—Ä—Ç—ã –≤—ã–ø–æ–ª–Ω–µ–Ω—ã —É—Å–ø–µ—à–Ω–æ\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üìä –ó–∞–≥—Ä—É–∂–µ–Ω–æ –∑–∞–ø–∏—Å–µ–π: 2896\n",
            "\n",
            "–ü—Ä–∏–º–µ—Ä –∑–∞–ø–∏—Å–∏:\n",
            "{\n",
            "  \"query\": \"–í —á–µ–º —Ä–∞–∑–Ω–∏—Ü–∞ –º–µ–∂–¥—É —Ä—ã–Ω–æ—á–Ω–æ–π –∫–∞–ø–∏—Ç–∞–ª–∏–∑–∞—Ü–∏–µ–π –∏ –±–∞–ª–∞–Ω—Å–æ–≤–æ–π —Å—Ç–æ–∏–º–æ—Å—Ç—å—é –∫–æ–º–ø–∞–Ω–∏–∏, –∏ –∫–∞–∫ —ç—Ç–∏ –ø–æ–∫–∞–∑–∞—Ç–µ–ª–∏ –∏—Å–ø–æ–ª—å–∑—É—é—Ç—Å—è –ø—Ä–∏ –æ—Ü–µ–Ω–∫–µ –∞–∫—Ü–∏–π?\",\n",
            "  \"doc_id\": \"2c8292ce-d169-4f24-9444-a5e32b541b1c\",\n",
            "  \"document_text\": \"–î–∞—Ç–∞ –ø—É–±–ª–∏–∫–∞—Ü–∏–∏: 10 –Ω–æ—è–±—Ä—è 2025\\n\\n**üéô**** –≠—Ç–æ –Ω–æ–≤—ã–π –≤—ã–ø—É—Å–∫ Top News!\\n**\\n–°–µ–≥–æ–¥–Ω—è –ò—Ä–∏–Ω–∞ –ò—Ä—Ç–µ–≥–æ–≤–∞ —Ç—Ä–∞–¥–∏—Ü–∏–æ–Ω–Ω–æ —Ä–∞—Å—Å–∫–∞–∂–µ—Ç –æ –¥–∏–Ω–∞–º–∏–∫–µ —Ä—ã–Ω–∫–∞ –∞–∫—Ü–∏–π –∏ –Ω–µ–º–Ω–æ–≥–æ –æ –Ω–æ–≤–æ—Å—Ç—è—Ö —ç–º–∏—Ç–µ–Ω—Ç–æ–≤ ‚Äî  **Ozon, –ú–¢–° –ë–∞–Ω–∫–∞, ¬´–†–æ—Å—Ç–µ–ª–µ–∫–æ–º–∞¬ª, ¬´–ò–Ω—Ç–µ—Ä –†–ê–û¬ª** –∏ **–ì—Ä—É–ø–ø—ã ¬´–ü–æ–∑–∏—Ç–∏–≤¬ª**. –ê –µ—â—ë ‚Äî [**–ø—Ä–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –î–û–ú.P–§**](https://t.me/c/2019406087/30987).\\n\\nüíö **–ï–∂–µ–Ω–µ–¥–µ–ª—å–Ω—ã–µ –Ω–æ–≤–æ—Å—Ç–∏ —É–∂–µ –∂–¥—É—Ç –≤–∞—Å, –∏–Ω–≤–µ—Å—Ç–æ—Ä—ã**!\\n\\n#OZON #MBNK #RTKM #IRAO #POSI\\n\\n–î–∞—Ç–∞ –ø—É–±–ª–∏–∫–∞—Ü–∏–∏: 10 –Ω–æ—è–±—Ä—è 2025\",\n",
            "  \"expected_router_decision\": \"NO\",\n",
            "  \"requires_rag\": false,\n",
            "  \"query_category\": \"domain_no_rag\"\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "# –ü—É—Ç—å –∫ –¥–∞—Ç–∞—Å–µ—Ç—É\n",
        "dataset_path = project_root / \"data\" / \"data_18.11.25\" / \"react_router_dataset.json\"\n",
        "\n",
        "with open(dataset_path, \"r\", encoding=\"utf-8\") as f:\n",
        "    dataset = json.load(f)\n",
        "\n",
        "print(f\"üìä –ó–∞–≥—Ä—É–∂–µ–Ω–æ –∑–∞–ø–∏—Å–µ–π: {len(dataset)}\")\n",
        "print(f\"\\n–ü—Ä–∏–º–µ—Ä –∑–∞–ø–∏—Å–∏:\")\n",
        "print(json.dumps(dataset[0], ensure_ascii=False, indent=2))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è GenerationService\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ GenerationService –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω\n",
            "   Router LLM Provider: qwen\n"
          ]
        }
      ],
      "source": [
        "# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º GenerationService\n",
        "generation_service = GenerationService(\n",
        "    retriever_url=settings.retriever_api_url,\n",
        ")\n",
        "\n",
        "print(f\"‚úÖ GenerationService –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω\")\n",
        "print(f\"   Router LLM Provider: {generation_service.router_llm_provider}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## –§—É–Ω–∫—Ü–∏—è –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è Router\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "async def get_router_prediction(query: str, llm_provider: str | None = None) -> Literal[\"YES\", \"NO\"]:\n",
        "    \"\"\"\n",
        "    –ü–æ–ª—É—á–∞–µ—Ç –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ ReAct Router –¥–ª—è –∑–∞–ø—Ä–æ—Å–∞.\n",
        "    \n",
        "    Args:\n",
        "        query: –ó–∞–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è\n",
        "        llm_provider: –ü—Ä–æ–≤–∞–π–¥–µ—Ä LLM –¥–ª—è –ø—Ä–∏–Ω—è—Ç–∏—è —Ä–µ—à–µ–Ω–∏—è\n",
        "    \n",
        "    Returns:\n",
        "        \"YES\" –µ—Å–ª–∏ –Ω—É–∂–µ–Ω retriever, \"NO\" –µ—Å–ª–∏ –Ω–µ –Ω—É–∂–µ–Ω\n",
        "    \"\"\"\n",
        "    use_retriever = await generation_service._should_use_retriever(\n",
        "        query=query,\n",
        "        session_id=None,  # –ë–µ–∑ –∏—Å—Ç–æ—Ä–∏–∏ –¥–∏–∞–ª–æ–≥–∞\n",
        "        llm_provider=\"qwen\",\n",
        "    )\n",
        "    return \"YES\" if use_retriever else \"NO\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## –û—Ü–µ–Ω–∫–∞ –Ω–∞ –¥–∞—Ç–∞—Å–µ—Ç–µ\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "async def evaluate_dataset(dataset: list[dict], batch_size: int = 10) -> list[dict]:\n",
        "    \"\"\"\n",
        "    –û—Ü–µ–Ω–∏–≤–∞–µ—Ç –¥–∞—Ç–∞—Å–µ—Ç –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã.\n",
        "    \n",
        "    Args:\n",
        "        dataset: –°–ø–∏—Å–æ–∫ –∑–∞–ø–∏—Å–µ–π –¥–∞—Ç–∞—Å–µ—Ç–∞\n",
        "        batch_size: –†–∞–∑–º–µ—Ä –±–∞—Ç—á–∞ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏\n",
        "    \n",
        "    Returns:\n",
        "        –°–ø–∏—Å–æ–∫ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ —Å –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è–º–∏\n",
        "    \"\"\"\n",
        "    results = []\n",
        "    \n",
        "    for i in range(0, len(dataset), batch_size):\n",
        "        batch = dataset[i:i + batch_size]\n",
        "        \n",
        "        # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –±–∞—Ç—á –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ\n",
        "        tasks = []\n",
        "        for record in batch:\n",
        "            query = record[\"query\"]\n",
        "            task = get_router_prediction(query)\n",
        "            tasks.append(task)\n",
        "        \n",
        "        predictions = await asyncio.gather(*tasks)\n",
        "        \n",
        "        # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã\n",
        "        for record, prediction in zip(batch, predictions):\n",
        "            expected = record.get(\"expected_router_decision\", \"YES\" if record.get(\"requires_rag\", True) else \"NO\")\n",
        "            requires_rag = record.get(\"requires_rag\", expected == \"YES\")\n",
        "            \n",
        "            results.append({\n",
        "                \"query\": record[\"query\"],\n",
        "                \"expected\": expected,\n",
        "                \"requires_rag\": requires_rag,\n",
        "                \"predicted\": prediction,\n",
        "                \"correct\": prediction == expected,\n",
        "            })\n",
        "        \n",
        "        if (i + batch_size) % 100 == 0 or i + batch_size >= len(dataset):\n",
        "            print(f\"‚úÖ –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ: {min(i + batch_size, len(dataset))} / {len(dataset)}\")\n",
        "    \n",
        "    return results\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üöÄ –ù–∞—á–∏–Ω–∞–µ–º –æ—Ü–µ–Ω–∫—É –Ω–∞ 2896 –∑–∞–ø—Ä–æ—Å–∞—Ö...\n",
            "‚úÖ –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ: 100 / 2896\n",
            "‚úÖ –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ: 200 / 2896\n",
            "‚úÖ –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ: 300 / 2896\n",
            "‚úÖ –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ: 400 / 2896\n",
            "‚úÖ –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ: 500 / 2896\n",
            "‚úÖ –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ: 600 / 2896\n",
            "‚úÖ –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ: 700 / 2896\n",
            "‚úÖ –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ: 800 / 2896\n",
            "‚úÖ –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ: 900 / 2896\n",
            "‚úÖ –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ: 1000 / 2896\n",
            "‚úÖ –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ: 1100 / 2896\n",
            "‚úÖ –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ: 1200 / 2896\n",
            "‚úÖ –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ: 1300 / 2896\n",
            "‚úÖ –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ: 1400 / 2896\n",
            "‚úÖ –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ: 1500 / 2896\n",
            "‚úÖ –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ: 1600 / 2896\n",
            "‚úÖ –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ: 1700 / 2896\n",
            "‚úÖ –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ: 1800 / 2896\n",
            "‚úÖ –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ: 1900 / 2896\n",
            "‚úÖ –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ: 2000 / 2896\n",
            "‚úÖ –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ: 2100 / 2896\n",
            "‚úÖ –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ: 2200 / 2896\n",
            "‚úÖ –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ: 2300 / 2896\n",
            "‚úÖ –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ: 2400 / 2896\n",
            "‚úÖ –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ: 2500 / 2896\n",
            "‚úÖ –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ: 2600 / 2896\n",
            "‚úÖ –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ: 2700 / 2896\n",
            "‚úÖ –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ: 2800 / 2896\n",
            "‚úÖ –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ: 2896 / 2896\n",
            "\n",
            "‚úÖ –û—Ü–µ–Ω–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞!\n"
          ]
        }
      ],
      "source": [
        "# –ó–∞–ø—É—Å–∫–∞–µ–º –æ—Ü–µ–Ω–∫—É\n",
        "print(f\"üöÄ –ù–∞—á–∏–Ω–∞–µ–º –æ—Ü–µ–Ω–∫—É –Ω–∞ {len(dataset)} –∑–∞–ø—Ä–æ—Å–∞—Ö...\")\n",
        "results = await evaluate_dataset(dataset, batch_size=50)\n",
        "print(f\"\\n‚úÖ –û—Ü–µ–Ω–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## –í—ã—á–∏—Å–ª–µ–Ω–∏–µ –º–µ—Ç—Ä–∏–∫\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "def calculate_metrics(results: list[dict]) -> dict:\n",
        "    \"\"\"\n",
        "    –í—ã—á–∏—Å–ª—è–µ—Ç –º–µ—Ç—Ä–∏–∫–∏ –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤.\n",
        "    \n",
        "    Args:\n",
        "        results: –°–ø–∏—Å–æ–∫ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ —Å –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è–º–∏\n",
        "    \n",
        "    Returns:\n",
        "        –°–ª–æ–≤–∞—Ä—å —Å –º–µ—Ç—Ä–∏–∫–∞–º–∏\n",
        "    \"\"\"\n",
        "    # –ü–æ–¥—Å—á–∏—Ç—ã–≤–∞–µ–º TP, FP, TN, FN\n",
        "    # –î–ª—è ReAct Router:\n",
        "    # - YES –æ–∑–Ω–∞—á–∞–µ—Ç \"–∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å retriever\" (positive class)\n",
        "    # - NO –æ–∑–Ω–∞—á–∞–µ—Ç \"–Ω–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å retriever\" (negative class)\n",
        "    \n",
        "    tp = 0  # True Positive: predicted=YES, actual=YES (requires_rag=True)\n",
        "    fp = 0  # False Positive: predicted=YES, actual=NO (requires_rag=False)\n",
        "    tn = 0  # True Negative: predicted=NO, actual=NO (requires_rag=False)\n",
        "    fn = 0  # False Negative: predicted=NO, actual=YES (requires_rag=True)\n",
        "    \n",
        "    for result in results:\n",
        "        predicted = result[\"predicted\"]\n",
        "        requires_rag = result[\"requires_rag\"]\n",
        "        \n",
        "        if predicted == \"YES\" and requires_rag:\n",
        "            tp += 1\n",
        "        elif predicted == \"YES\" and not requires_rag:\n",
        "            fp += 1\n",
        "        elif predicted == \"NO\" and not requires_rag:\n",
        "            tn += 1\n",
        "        elif predicted == \"NO\" and requires_rag:\n",
        "            fn += 1\n",
        "    \n",
        "    # –í—ã—á–∏—Å–ª—è–µ–º –º–µ—Ç—Ä–∏–∫–∏\n",
        "    precision = tp / (tp + fp) if (tp + fp) > 0 else 0.0\n",
        "    recall = tp / (tp + fn) if (tp + fn) > 0 else 0.0\n",
        "    f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0.0\n",
        "    accuracy = (tp + tn) / (tp + fp + tn + fn) if (tp + fp + tn + fn) > 0 else 0.0\n",
        "    \n",
        "    return {\n",
        "        \"tp\": tp,\n",
        "        \"fp\": fp,\n",
        "        \"tn\": tn,\n",
        "        \"fn\": fn,\n",
        "        \"precision\": precision,\n",
        "        \"recall\": recall,\n",
        "        \"f1\": f1,\n",
        "        \"accuracy\": accuracy,\n",
        "        \"total\": len(results),\n",
        "    }\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üìä –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –æ—Ü–µ–Ω–∫–∏ ReAct Router:\n",
            "============================================================\n",
            "–í—Å–µ–≥–æ –∑–∞–ø—Ä–æ—Å–æ–≤: 2896\n",
            "\n",
            "Confusion Matrix:\n",
            "  TP (True Positive):  1445  |  –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–æ YES, —Ñ–∞–∫—Ç–∏—á–µ—Å–∫–∏ YES\n",
            "  FP (False Positive):  815  |  –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–æ YES, —Ñ–∞–∫—Ç–∏—á–µ—Å–∫–∏ NO\n",
            "  TN (True Negative):   633  |  –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–æ NO,  —Ñ–∞–∫—Ç–∏—á–µ—Å–∫–∏ NO\n",
            "  FN (False Negative):    3  |  –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–æ NO,  —Ñ–∞–∫—Ç–∏—á–µ—Å–∫–∏ YES\n",
            "\n",
            "–ú–µ—Ç—Ä–∏–∫–∏:\n",
            "  Precision: 0.6394  (TP / (TP + FP))\n",
            "  Recall:    0.9979  (TP / (TP + FN))\n",
            "  F1-score:  0.7794\n",
            "  Accuracy:  0.7175  ((TP + TN) / Total)\n",
            "============================================================\n"
          ]
        }
      ],
      "source": [
        "# –í—ã—á–∏—Å–ª—è–µ–º –º–µ—Ç—Ä–∏–∫–∏\n",
        "metrics = calculate_metrics(results)\n",
        "\n",
        "print(\"üìä –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –æ—Ü–µ–Ω–∫–∏ ReAct Router:\")\n",
        "print(\"=\" * 60)\n",
        "print(f\"–í—Å–µ–≥–æ –∑–∞–ø—Ä–æ—Å–æ–≤: {metrics['total']}\")\n",
        "print(f\"\\nConfusion Matrix:\")\n",
        "print(f\"  TP (True Positive):  {metrics['tp']:4d}  |  –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–æ YES, —Ñ–∞–∫—Ç–∏—á–µ—Å–∫–∏ YES\")\n",
        "print(f\"  FP (False Positive): {metrics['fp']:4d}  |  –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–æ YES, —Ñ–∞–∫—Ç–∏—á–µ—Å–∫–∏ NO\")\n",
        "print(f\"  TN (True Negative):  {metrics['tn']:4d}  |  –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–æ NO,  —Ñ–∞–∫—Ç–∏—á–µ—Å–∫–∏ NO\")\n",
        "print(f\"  FN (False Negative): {metrics['fn']:4d}  |  –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–æ NO,  —Ñ–∞–∫—Ç–∏—á–µ—Å–∫–∏ YES\")\n",
        "print(f\"\\n–ú–µ—Ç—Ä–∏–∫–∏:\")\n",
        "print(f\"  Precision: {metrics['precision']:.4f}  (TP / (TP + FP))\")\n",
        "print(f\"  Recall:    {metrics['recall']:.4f}  (TP / (TP + FN))\")\n",
        "print(f\"  F1-score:  {metrics['f1']:.4f}\")\n",
        "print(f\"  Accuracy:  {metrics['accuracy']:.4f}  ((TP + TN) / Total)\")\n",
        "print(\"=\" * 60)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "‚ùå False Positive (FP) –æ—à–∏–±–∫–∏: 815\n",
            "   Router —Ä–µ—à–∏–ª –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å retriever, –Ω–æ —ç—Ç–æ –±—ã–ª–æ –Ω–µ –Ω—É–∂–Ω–æ\n",
            "\n",
            "–ü—Ä–∏–º–µ—Ä—ã FP –æ—à–∏–±–æ–∫:\n",
            "\n",
            "  1. –í —á–µ–º —Ä–∞–∑–Ω–∏—Ü–∞ –º–µ–∂–¥—É —Ä—ã–Ω–æ—á–Ω–æ–π –∫–∞–ø–∏—Ç–∞–ª–∏–∑–∞—Ü–∏–µ–π –∏ –±–∞–ª–∞–Ω—Å–æ–≤–æ–π —Å—Ç–æ–∏–º–æ—Å—Ç—å—é –∫–æ–º–ø–∞–Ω–∏–∏, –∏ –∫–∞–∫ —ç—Ç–∏ –ø–æ–∫–∞–∑–∞—Ç–µ–ª–∏ –∏...\n",
            "\n",
            "  2. –ö–∞–∫–∏–µ —Ñ–∞–∫—Ç–æ—Ä—ã –≤–ª–∏—è—é—Ç –Ω–∞ –≤—ã–±–æ—Ä –º–µ–∂–¥—É –¥–æ–ª–≥–æ–≤—ã–º–∏ –∏ –¥–æ–ª–µ–≤—ã–º–∏ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–∞–º–∏ –≤ –∏–Ω–≤–µ—Å—Ç–∏—Ü–∏–æ–Ω–Ω–æ–º –ø–æ—Ä—Ç—Ñ–µ–ª–µ?...\n",
            "\n",
            "  3. –ö–∞–∫–∏–µ —Ñ–∞–∫—Ç–æ—Ä—ã –≤–ª–∏—è—é—Ç –Ω–∞ —Å—Ç–æ–∏–º–æ—Å—Ç—å –æ–ø—Ü–∏–æ–Ω–æ–≤ –Ω–∞ –∞–∫—Ü–∏–∏ –∏ –∫–∞–∫ –æ–Ω–∏ –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤—É—é—Ç –º–µ–∂–¥—É —Å–æ–±–æ–π?...\n",
            "\n",
            "  5. –ö–∞–∫–∏–µ —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏ –∏–Ω–≤–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è –º–æ–∂–Ω–æ —Ä–µ–∞–ª–∏–∑–æ–≤–∞—Ç—å —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º –ø—Ä–æ–∏–∑–≤–æ–¥–Ω—ã—Ö –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–æ–≤, –Ω–µ —Ç—Ä–µ–±—É...\n",
            "\n",
            "  7. –û–±—ä—è—Å–Ω–∏—Ç–µ, –ø–æ—á–µ–º—É –æ–∂–∏–¥–∞–Ω–∏—è –∏–∑–º–µ–Ω–µ–Ω–∏—è –∫–ª—é—á–µ–≤–æ–π —Å—Ç–∞–≤–∫–∏ –º–æ–≥—É—Ç –≤–ª–∏—è—Ç—å –Ω–∞ –¥–∏–Ω–∞–º–∏–∫—É –∞–∫—Ü–∏–π –≤ –æ—Ç—Ä–∞—Å–ª–∏ –Ω–µ–¥–≤–∏–∂...\n",
            "\n",
            "‚ùå False Negative (FN) –æ—à–∏–±–∫–∏: 3\n",
            "   Router —Ä–µ—à–∏–ª –ù–ï –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å retriever, –Ω–æ –æ–Ω –±—ã–ª –Ω—É–∂–µ–Ω\n",
            "\n",
            "–ü—Ä–∏–º–µ—Ä—ã FN –æ—à–∏–±–æ–∫:\n",
            "\n",
            "  1183. –ö–∞–∫ –º–æ–∂–Ω–æ –ø—Ä–æ–≤–µ—Ä–∏—Ç—å, –∫—Ç–æ –ø–æ–ª—É—á–∏–ª –¥–æ—Å—Ç—É–ø –∫ –º–æ–µ–º—É –∞–∫–∫–∞—É–Ω—Ç—É –≤ –¢–µ–ª–µ–≥—Ä–∞–º–µ, –∏ –≥–¥–µ –Ω–∞–π—Ç–∏ —ç—Ç—É –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é?...\n",
            "\n",
            "  1583. –ì–¥–µ –º–æ–∂–Ω–æ –ø–æ—Å–º–æ—Ç—Ä–µ—Ç—å —Ç—Ä–∞–Ω—Å–ª—è—Ü–∏—é –ø–ª–µ–Ω–∞—Ä–Ω–æ–π –¥–∏—Å–∫—É—Å—Å–∏–∏ –∫–æ–Ω—Ñ–µ—Ä–µ–Ω—Ü–∏–∏ ¬´–§–æ–∫—É—Å –Ω–∞ –∫–ª–∏–µ–Ω—Ç–∞¬ª?...\n",
            "\n",
            "  2158. –ö–∞–∫–∏–µ —Ö—ç—à—Ç–µ–≥–∏ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω—ã –≤ —Å–æ–æ–±—â–µ–Ω–∏–∏ –æ –Ω–æ–≤–æ–º –≤—ã–ø—É—Å–∫–µ –ø–æ–¥–∫–∞—Å—Ç–∞?...\n"
          ]
        }
      ],
      "source": [
        "# –°–æ–∑–¥–∞–µ–º DataFrame –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞\n",
        "df = pd.DataFrame(results)\n",
        "\n",
        "# –û—à–∏–±–∫–∏ —Ç–∏–ø–∞ FP (False Positive)\n",
        "fp_errors = df[(df[\"predicted\"] == \"YES\") & (df[\"requires_rag\"] == False)]\n",
        "print(f\"\\n‚ùå False Positive (FP) –æ—à–∏–±–∫–∏: {len(fp_errors)}\")\n",
        "print(\"   Router —Ä–µ—à–∏–ª –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å retriever, –Ω–æ —ç—Ç–æ –±—ã–ª–æ –Ω–µ –Ω—É–∂–Ω–æ\")\n",
        "if len(fp_errors) > 0:\n",
        "    print(\"\\n–ü—Ä–∏–º–µ—Ä—ã FP –æ—à–∏–±–æ–∫:\")\n",
        "    for idx, row in fp_errors.head(5).iterrows():\n",
        "        print(f\"\\n  {idx + 1}. {row['query'][:100]}...\")\n",
        "\n",
        "# –û—à–∏–±–∫–∏ —Ç–∏–ø–∞ FN (False Negative)\n",
        "fn_errors = df[(df[\"predicted\"] == \"NO\") & (df[\"requires_rag\"] == True)]\n",
        "print(f\"\\n‚ùå False Negative (FN) –æ—à–∏–±–∫–∏: {len(fn_errors)}\")\n",
        "print(\"   Router —Ä–µ—à–∏–ª –ù–ï –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å retriever, –Ω–æ –æ–Ω –±—ã–ª –Ω—É–∂–µ–Ω\")\n",
        "if len(fn_errors) > 0:\n",
        "    print(\"\\n–ü—Ä–∏–º–µ—Ä—ã FN –æ—à–∏–±–æ–∫:\")\n",
        "    for idx, row in fn_errors.head(5).iterrows():\n",
        "        print(f\"\\n  {idx + 1}. {row['query'][:100]}...\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "tplexity-AFAH5PUx-py3.12",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
